{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPY165cDDJTz"
   },
   "source": [
    "# Lab. 2: Stochastic global optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### <u>The goal of this laboratory is to study the application of stochastic global search algorithms on different benchmark functions.</u>\n",
    "\n",
    "We will study two methods:\n",
    "- *DIRECT*\n",
    "- *Basin-hopping*\n",
    "\n",
    "Moreover, we will study the effect of their parameters on the outcome of the search.\n",
    "\n",
    "---\n",
    "\n",
    "Getting started: the following code cell contains the core functions that we will use. Hence, **remember to run it every time the runtime is reconnected**.\n",
    "\n",
    "You can find a wrapper function for the  two algorithm, together with a wrapper for the benchmark function.\n",
    "As regards the *OptFun* class, the constructor takes as input a benchmark function (we will see later what functions are available). The relevant methods  are 4:\n",
    "1.   *Minima*: return the minimum of the function. The position can be obtained by the parameter *position* and the function value from the *score* parameter.\n",
    "2.   *Bounds*: returns where the function is defined\n",
    "3.   *Heatmap*: show a heatmap of the function highlighting the points visited by the local search (use with 2d function)\n",
    "4.   *plot*: show the trend of the points visited by the local search (use with 1d function)\n",
    "5.   *trend*: show the best points find during the optmization process.\n",
    "\n",
    "Each instance of *OptFun* stores the history of the point at which the function has been evaluated. The history is never cleaned and can be obtained through *OptFun.history*. Hence, if you reuse the class instance remember to clean the history (*OptFun.history = list()*).\n",
    "\n",
    "---\n",
    "\n",
    "The benchmark functions available comes from the *benchmark_functions* library (imported as *bf*).\n",
    "Example of the functions that can be used are the *Hypersphere*, the *Rastrign* the *DeJong5* and the Keane.\n",
    "The complete list of functions available can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions) or you can print it with *dir(bf)*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Czm90e6dDNxa"
   },
   "source": [
    "#### Base code to run every time the runtime is reconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1709841654724,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "k9t_QSgtDGjU"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "import benchmark_functions as bf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import OptimizeResult as spResult\n",
    "from scipy.optimize import basinhopping as spbasinhopping\n",
    "from scipydirect import OptimizeResult as spdResult\n",
    "from scipydirect import minimize as spdirect\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (22, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "3hAGFGMlDQcY"
   },
   "outputs": [],
   "source": [
    "class OptFun:\n",
    "    def __init__(self, wf: bf.BenchmarkFunction) -> None:\n",
    "        self.f = wf\n",
    "        self.history: list[list[float]] = []\n",
    "\n",
    "    def __call__(self, x0: list[float]) -> float:\n",
    "        self.history.append(deepcopy(x0))\n",
    "        return self.f(x0)  # type: ignore\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.f.name()\n",
    "\n",
    "    def minima(self) -> list[bf.fil.Optimum]:\n",
    "        \"\"\"\n",
    "        Returns a list of Optimum objects of the known global minima. If there aren't any minima, an empty list value will be returned instead;\n",
    "\n",
    "        Returns:\n",
    "        - List of objects of class \"benchmark_functions.functions_info_loader.Optimum\"\n",
    "        - For each object:\n",
    "          - Access to 'position' parameter to get the axis values\n",
    "          - Access to 'score' parameter to get the value of the function\n",
    "        \"\"\"\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounds(self) -> list[tuple[float, float]]:\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def found_minimum(self) -> list[float]:\n",
    "        minimum = self.history[0]\n",
    "        for x in self.history:\n",
    "            if self.f(x) < self.f(minimum):  # type: ignore\n",
    "                minimum = x\n",
    "        return minimum\n",
    "\n",
    "    def plot(self, fn: Optional[str] = None) -> None:\n",
    "        plt.clf()\n",
    "        ax1: plt.Axes\n",
    "        ax2: plt.Axes\n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        f.suptitle(\"Benchmark Function: \" + self.name)\n",
    "\n",
    "        # heatmap\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], 100)\n",
    "        if self.f.n_dimensions() > 1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], 100)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray(\n",
    "                [\n",
    "                    [self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))]\n",
    "                    for i in range(len(X))\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Function has only one dimension\")\n",
    "\n",
    "        ax1.contour(x, y, Z, 15, linewidths=0.5, colors=\"k\")  # hight lines\n",
    "        contour = ax1.contourf(\n",
    "            x, y, Z, 15, cmap=\"viridis\", vmin=Z.min(), vmax=Z.max()\n",
    "        )  # heat map\n",
    "        ax1.set_xlabel(\"x\")\n",
    "        ax1.set_ylabel(\"y\")\n",
    "        cbar = plt.colorbar(contour, ax=ax1)\n",
    "        cbar.set_label(\"z\")\n",
    "        if len(self.history) > 0:  # plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            xdata = xdata[1:]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            ydata = ydata[1:]\n",
    "\n",
    "            ax1.plot(xdata, ydata, \"or-\", markersize=5, linewidth=1.5, label=\"Path\")\n",
    "            ax1.plot(\n",
    "                xdata[0],\n",
    "                ydata[0],\n",
    "                marker=\"X\",\n",
    "                markersize=13,\n",
    "                color=\"black\",\n",
    "                label=\"Start\",\n",
    "            )\n",
    "\n",
    "            ax1.plot(\n",
    "                xdata[-1],\n",
    "                ydata[-1],\n",
    "                marker=\"P\",\n",
    "                markersize=13,\n",
    "                color=\"white\",\n",
    "                label=\"End\",\n",
    "            )\n",
    "            ax1.legend(loc=\"upper right\")\n",
    "\n",
    "        # convergence\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        values = values[1:]\n",
    "        min: float = self.f.minima()[0].score  # type: ignore\n",
    "\n",
    "        ax2.plot(values, label=\"Scores\", marker=\"o\")\n",
    "\n",
    "        ax2.axhline(min, color=\"r\", label=\"optimum\", linestyle=\"dashed\")\n",
    "        ax2.set_xlabel(\"Iterations/Evaluations\")  # TODO\n",
    "        ax2.set_ylabel(\"f(x)\")\n",
    "        ax2.legend()\n",
    "\n",
    "        if fn is not None:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(\n",
    "        self, bounds: tuple[list[float], list[float]]\n",
    "    ) -> list[tuple[float, float]]:\n",
    "        new_bounds = []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self) -> int:\n",
    "        return len(self.history)\n",
    "\n",
    "\n",
    "def grid_search(\n",
    "    f: OptFun,\n",
    "    step_size: Optional[float] = None,\n",
    "    number_of_steps: Optional[float] = None,\n",
    "    minimization: bool = True,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the grid_search algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - step_size: the step size\n",
    "    - number_of_steps: the total number of steps\n",
    "    - minimization: boolean, True if looking for minimum, False if looking for maximum; defauls True\n",
    "\n",
    "    Returns:\n",
    "    - best value found\n",
    "    \"\"\"\n",
    "\n",
    "    if step_size is not None:\n",
    "        range_step_size = step_size\n",
    "    elif number_of_steps is not None:\n",
    "        range_step_size = int(np.floor(np.sqrt(number_of_steps)))\n",
    "    else:\n",
    "        raise ValueError(\"Please provide at least the step_size or the number_of_steps\")\n",
    "\n",
    "    bounds = f.bounds()\n",
    "    best = float(\"inf\") if minimization else float(\"sup\")\n",
    "\n",
    "    for x in np.arange(bounds[0][0], bounds[0][1], range_step_size):\n",
    "        for y in np.arange(bounds[1][0], bounds[1][1], range_step_size):\n",
    "            current = f([x, y])\n",
    "            if minimization:\n",
    "                if current < best:\n",
    "                    best = current\n",
    "            else:\n",
    "                if current > best:\n",
    "                    best = current\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def direct(\n",
    "    func: OptFun,\n",
    "    eps: float = 1e-4,\n",
    "    maxiter: int = 1000,\n",
    "    maxfneval: int = 1000,\n",
    "    optima: Optional[int] = None,\n",
    "    error_tollerance: Optional[int] = None,\n",
    ") -> tuple[spdResult, list[float], float]:\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the DIRECT algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - eps: regulates the trade-off between local and global exploration.\n",
    "            The smaller the eps, the finer the granularity of the search.\n",
    "    - maxiter: maximum number of iterations\n",
    "    - maxfneval: maximum number of function evaluations\n",
    "    \"\"\"\n",
    "    bounds = func.bounds()\n",
    "    results = spdirect(\n",
    "        func,\n",
    "        bounds=bounds,\n",
    "        eps=eps,\n",
    "        maxT=maxiter,\n",
    "        maxf=maxfneval,\n",
    "        fglobal=-1e100,\n",
    "        fglper=0.001,\n",
    "        volper=-1.0,\n",
    "        sigmaper=-1.0,\n",
    "    )\n",
    "    # best_position: list[float] = results.x\n",
    "    # best_score: float = results.fun\n",
    "    history: list[float] = [func.f(v) for v in func.history]  # type: ignore\n",
    "    history = history[1:]\n",
    "    best_score = min(history)\n",
    "    best_position = func.history[history.index(best_score)]\n",
    "    return results, best_position, best_score\n",
    "\n",
    "\n",
    "def basinhopping(\n",
    "    f: OptFun,\n",
    "    x0: Sequence[float],\n",
    "    T: float = 1.0,\n",
    "    stepsize: float = 0.5,\n",
    "    stepsize_interval: int = 50,\n",
    "    maxiter: int = 1000,\n",
    "    bounds: Optional[Sequence[tuple[float, float]]] = None,\n",
    ") -> spResult:\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the Basin-hopping algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - x0: starting point for the search process\n",
    "    - T: temperature parameter\n",
    "    - stepsize: maximum step size for random displacement\n",
    "    - stepsize_interval: interval for the update of the step size\n",
    "    - maxiter: maximum number of iterations\n",
    "    \"\"\"\n",
    "    minimizer_kwargs = {\"method\": \"L-BFGS-B\", \"bounds\": bounds}\n",
    "    return spbasinhopping(\n",
    "        f,\n",
    "        x0,\n",
    "        niter=maxiter,\n",
    "        T=T,\n",
    "        stepsize=stepsize,\n",
    "        minimizer_kwargs=minimizer_kwargs,\n",
    "        take_step=None,\n",
    "        accept_test=None,\n",
    "        callback=None,\n",
    "        interval=stepsize_interval,\n",
    "        disp=False,\n",
    "        niter_success=None,\n",
    "        seed=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "lPVkBFXeG-Mv"
   },
   "outputs": [],
   "source": [
    "def printClassInitArgs(class_obj: bf.BenchmarkFunction) -> None:\n",
    "    print(f\"{class_obj.name()}\")\n",
    "    signature = inspect.signature(class_obj.__init__).parameters\n",
    "    print(\"-------------------------------\")\n",
    "    for name, parameter in signature.items():\n",
    "        if name != \"opposite\":\n",
    "            print(\"Name: \", name, \"\\nDefault value:\", parameter.default)\n",
    "            # print(\"Annotation:\", parameter.annotation, \"\\nKind:\", parameter.kind)\n",
    "            print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQMoNUgSDTbj"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "#### Solve the following exercises, and answer these questions at the end:\n",
    "\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "fbF-V__PHGPk",
    "outputId": "7c73f133-472b-473f-d318-8ee84dce14e9"
   },
   "outputs": [],
   "source": [
    "# BE AWARE: check the arguments each benchmark function takes\n",
    "# if you're not sure, you can check the arguments by using the printClassInitArgs function\n",
    "print(dir(bf))\n",
    "printClassInitArgs(bf.Hypersphere())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mucSZghNDWCL"
   },
   "source": [
    "## Exercise 1/2: DIRECT\n",
    "In this first exercise we will use [DIRECT](https://scipydirect.readthedocs.io/en/latest/reference.html) as a search algorithm\n",
    "\n",
    "More suited for functions with a single global optimum\n",
    "\n",
    "### Questions\n",
    "- How does the eps parameter influence the search process?\n",
    "- How does the number of maximum iterations influence the search process? (To note: the maximum iterations and maximum number of evalutions are the soly metrics used to reach a stopping condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.Rosenbrock()\n",
    "\n",
    "max_iter = 50\n",
    "max_eval = 250\n",
    "\n",
    "eps = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "for e in eps:\n",
    "    func = OptFun(benchmark)\n",
    "    res, best_location, best_value = direct(func, e, max_iter, max_eval)\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"Eps: \", e)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong3()\n",
    "\n",
    "max_iter = 50\n",
    "max_eval = 250\n",
    "\n",
    "eps = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "for e in eps:\n",
    "    func = OptFun(benchmark)\n",
    "    res, best_location, best_value = direct(func, e, max_iter, max_eval)\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"Eps: \", e)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1709841656248,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "cCKNQaaSDTma",
    "outputId": "c107162c-7370-45b7-fef2-250ff0808143"
   },
   "outputs": [],
   "source": [
    "benchmark = bf.Keane()\n",
    "\n",
    "max_iter = 50\n",
    "max_eval = 250\n",
    "\n",
    "eps = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "for e in eps:\n",
    "    func = OptFun(benchmark)\n",
    "    res, best_location, best_value = direct(func, e, max_iter, max_eval)\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"Eps: \", e)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.Ackley()\n",
    "\n",
    "max_iter = 50  # TODO: try different values\n",
    "max_eval = 250  # TODO try different values\n",
    "\n",
    "eps = [10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "for e in eps:\n",
    "    func = OptFun(benchmark)\n",
    "    res, best_location, best_value = direct(func, e, max_iter, max_eval)\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"Eps: \", e)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.Rosenbrock()\n",
    "\n",
    "max_iters = [50, 100, 500, 1000]\n",
    "max_evals = [250, 500, 2500, 5000]\n",
    "\n",
    "eps = 0.1\n",
    "for max_iter in max_iters:\n",
    "    for max_eval in max_evals:\n",
    "        func = OptFun(benchmark)\n",
    "        res, best_location, best_value = direct(func, eps, max_iter, max_eval)\n",
    "        print(\"Function: \", func.name)\n",
    "        print(\"Max iterations: \", max_iter)\n",
    "        print(\"Max evaluations: \", max_eval)\n",
    "        print(\"Minima value: \", func.minima()[0].score)\n",
    "        print(\"Best value found:\", best_value)\n",
    "        print(\"Minima position: \", func.minima()[0].position)\n",
    "        print(\"Best location found:\", best_location)\n",
    "        # print(res)\n",
    "        func.plot()\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong5()\n",
    "\n",
    "max_iters = [50, 100, 500, 1000]\n",
    "max_evals = [250, 500, 1000, 2500]\n",
    "\n",
    "eps = 0.01\n",
    "for max_eval in max_evals:\n",
    "    for max_iter in max_iters:\n",
    "        func = OptFun(benchmark)\n",
    "        res, best_location, best_value = direct(func, eps, max_iter, max_eval)\n",
    "        print(\"Function: \", func.name)\n",
    "        print(\"Max iterations: \", max_iter)\n",
    "        print(\"Max evaluations: \", max_eval)\n",
    "        print(\"Minima value: \", func.minima()[0].score)\n",
    "        print(\"Best value found:\", best_value)\n",
    "        print(\"Minima position: \", func.minima()[0].position)\n",
    "        print(\"Best location found:\", best_location)\n",
    "        print(res)\n",
    "        func.plot()\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong5()\n",
    "\n",
    "max_iters = [50, 100, 500, 1000]\n",
    "max_evals = [250, 500, 1000, 2500]\n",
    "\n",
    "eps = 0.01\n",
    "for max_iter in max_iters:\n",
    "    for max_eval in max_evals:\n",
    "        func = OptFun(benchmark)\n",
    "        res, best_location, best_value = direct(func, eps, max_iter, max_eval)\n",
    "        print(\"Function: \", func.name)\n",
    "        print(\"Max iterations: \", max_iter)\n",
    "        print(\"Max evaluations: \", max_eval)\n",
    "        print(\"Minima value: \", func.minima()[0].score)\n",
    "        print(\"Best value found:\", best_value)\n",
    "        print(\"Minima position: \", func.minima()[0].position)\n",
    "        print(\"Best location found:\", best_location)\n",
    "        print(res)\n",
    "        func.plot()\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the efforts in exploring the local minima\n",
    "benchmark = bf.Griewank(zoom=1)\n",
    "\n",
    "max_iter = 50  # TODO: try different values\n",
    "max_eval = 250  # TODO try different values\n",
    "\n",
    "eps = [0.001]\n",
    "for e in eps:\n",
    "    func = OptFun(benchmark)\n",
    "    res, best_location, best_value = direct(func, e, max_iter, max_eval)\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"Eps: \", e)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kvWwb0tDbSZ"
   },
   "source": [
    "## Exercise 2/2: BASIN-HOPPING\n",
    "In this exercise we will use [Basin-hopping](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html) as a search algorithm\n",
    "\n",
    "More efffective on functions with multiple local minima\n",
    "\n",
    "### Questions\n",
    "- What is the influence of the following parameters on the search process?\n",
    "  - **T:** The “temperature” parameter for the acceptance or rejection criterion. Higher “temperatures” mean that larger jumps in function value will be accepted. For best results T should be comparable to the separation (in function value) between local minima;\n",
    "  - **stepsize:** Maximum step size for use in the random displacement;\n",
    "  - **stepsize_interval:** interval for how often to update the stepsize;\n",
    "  - **niter:** The number of basin-hopping iterations.\n",
    "- How does the number of maximum iterations influence the search process?\n",
    "- How does the starting point influence the search process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong5()\n",
    "\n",
    "x_0 = [0.0, 0.0]\n",
    "stepsize = 10.0\n",
    "stepsize_interval = 20\n",
    "n_iter = 100\n",
    "\n",
    "T = [100.0, 10.0, 1, 0.1, 0.01, 0.001]\n",
    "for t in T:\n",
    "    func = OptFun(benchmark)\n",
    "    res = basinhopping(func, x_0, t, stepsize, stepsize_interval, n_iter, func.bounds())\n",
    "    best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"T: \", t)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong5()\n",
    "\n",
    "x_0 = [10.0, 10.0]\n",
    "stepsizes = [50.0, 10.0, 1.0, 0.1, 0.01]\n",
    "stepsize_interval = 20\n",
    "n_iter = 100\n",
    "\n",
    "T = 0.1\n",
    "for stepsize in stepsizes:\n",
    "    func = OptFun(benchmark)\n",
    "    res = basinhopping(func, x_0, T, stepsize, stepsize_interval, n_iter, func.bounds())\n",
    "    best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"T: \", T)\n",
    "    print(\"Stepsize: \", stepsize)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.Rastrigin()\n",
    "\n",
    "x_0 = [-4.0, 4.0]\n",
    "stepsize = 0.1\n",
    "stepsize_interval = 25\n",
    "n_iter = 100\n",
    "\n",
    "T = [20.0]\n",
    "for t in T:\n",
    "    func = OptFun(benchmark)\n",
    "    res = basinhopping(\n",
    "        func, x_0, t, stepsize, stepsize_interval, n_iter, bounds=func.bounds()\n",
    "    )\n",
    "    best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"T: \", t)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "AD_oevi5DVJS",
    "outputId": "7d59e529-8bba-4f53-e8d6-7b39e000a7a7"
   },
   "outputs": [],
   "source": [
    "benchmark = bf.Keane()\n",
    "\n",
    "x_0 = [8.0, 8.0]\n",
    "stepsize = 1.5\n",
    "stepsize_interval = 25\n",
    "n_iter = 250\n",
    "\n",
    "T = [100.0, 10.0, 1.0, 0.1, 0.01, 0.001]\n",
    "for t in T:\n",
    "    func = OptFun(benchmark)\n",
    "    res = basinhopping(\n",
    "        func, x_0, t, stepsize, stepsize_interval, n_iter, bounds=func.bounds()\n",
    "    )\n",
    "    best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "    print(\"Function: \", func.name)\n",
    "    print(\"T: \", t)\n",
    "    print(\"Minima value: \", func.minima()[0].score)\n",
    "    print(\"Best value found:\", best_value)\n",
    "    print(\"Minima position: \", func.minima()[0].position)\n",
    "    print(\"Best location found:\", best_location)\n",
    "    # print(res)\n",
    "    func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.Rosenbrock()\n",
    "\n",
    "x_0 = [-2.0, -2.0]\n",
    "n_iter = 25\n",
    "T = 0.01\n",
    "\n",
    "stepsize_interval = 10\n",
    "stepsize = 0.1\n",
    "func = OptFun(benchmark)\n",
    "res = basinhopping(\n",
    "    func, x_0, T, stepsize, stepsize_interval, n_iter, bounds=func.bounds()\n",
    ")\n",
    "best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "print(\"Function: \", func.name)\n",
    "print(\"Step size: \", stepsize)\n",
    "print(\"Step size interval: \", stepsize_interval)\n",
    "print(\"Minima value: \", func.minima()[0].score)\n",
    "print(\"Best value found:\", best_value)\n",
    "print(\"Minima position: \", func.minima()[0].position)\n",
    "print(\"Best location found:\", best_location)\n",
    "# print(res)\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.EggHolder()\n",
    "\n",
    "x_0 = [-2.0, -2.0]\n",
    "n_iter = 100\n",
    "T = 0.1\n",
    "\n",
    "stepsize_intervals = [10, 25, 50, 100]\n",
    "stepsizes = [1.0, 10.0, 50.0, 100.0]\n",
    "for stepsize in stepsizes:\n",
    "    for stepsize_interval in stepsize_intervals:\n",
    "        func = OptFun(benchmark)\n",
    "        res = basinhopping(\n",
    "            func, x_0, T, stepsize, stepsize_interval, n_iter, func.bounds()\n",
    "        )\n",
    "        best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "        print(\"Function: \", func.name)\n",
    "        print(\"Step size: \", stepsize)\n",
    "        print(\"Step size interval: \", stepsize_interval)\n",
    "        print(\"Minima value: \", func.minima()[0].score)\n",
    "        print(\"Best value found:\", best_value)\n",
    "        print(\"Minima position: \", func.minima()[0].position)\n",
    "        print(\"Best location found:\", best_location)\n",
    "        # print(res)\n",
    "        func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = bf.DeJong3()\n",
    "\n",
    "x_0 = [2.5, 2.5]\n",
    "n_iter = 100\n",
    "T = 1\n",
    "\n",
    "stepsize_intervals = [10, 25, 50, 100]\n",
    "stepsizes = [0.01, 0.1, 0.5, 1.0]\n",
    "for stepsize in stepsizes:\n",
    "    for stepsize_interval in stepsize_intervals:\n",
    "        func = OptFun(benchmark)\n",
    "        res = basinhopping(\n",
    "            func, x_0, T, stepsize, stepsize_interval, n_iter, bounds=func.bounds()\n",
    "        )\n",
    "        best_value, best_location = res[\"fun\"], res[\"x\"]\n",
    "\n",
    "        print(\"Function: \", func.name)\n",
    "        print(\"Step size: \", stepsize)\n",
    "        print(\"Step size interval: \", stepsize_interval)\n",
    "        print(\"Minima value: \", func.minima()[0].score)\n",
    "        print(\"Best value found:\", best_value)\n",
    "        print(\"Minima position: \", func.minima()[0].position)\n",
    "        print(\"Best location found:\", best_location)\n",
    "        # print(res)\n",
    "        func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lphxcGsFDjbT"
   },
   "source": [
    "## Final questions\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "XR0d_Yi8DkXy"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
