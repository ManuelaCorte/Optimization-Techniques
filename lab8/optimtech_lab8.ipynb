{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMEyDajmtjgy"
   },
   "source": [
    "# Lab. 8: Multi-Objective Optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### <u>The goal of this lab is to study different Multi-Objective Optimization approaches.</u>\n",
    "\n",
    "For this problem, we will use two problems as benchmarks:\n",
    "1. Kursawe's function:\n",
    "$\\underset{x}{min}\\begin{cases}f_1(x) &= \\sum_{i=1}^{n-1} \\left[-10e^{-0.2\\sqrt{x_i^2 + x_{i+1}^2}}\\right] \\\\ f_2(x) &= \\sum_{i=1}^n \\left[|x_i|^{0.8} + 5\\sin(x_i)^3\\right] \\\\\\end{cases}$ s.t. $x_i \\in [-5, 5]; i \\in [1,n]$\n",
    "2. Multiple-disk clutch brake optimization: This real world optimization problem consists in the optimization of 5 paramters concernining multiple-disk clutch brakes. The parameters are shown visually in the image below.\n",
    "\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "(Image taken from Deb and Srinivasan, \"Innovization: Innovative Design Principles Through Optimization\")\n",
    "\n",
    "Two conflicting objectives are considered in the problem of this exercise:\n",
    "1. minimization of break system mass(in kg)\n",
    "2. minimization of stopping time(in s).\n",
    "\n",
    "This problem is characterzied by five decision variables that are:\n",
    "1. $r_i$ the inner radius in mm. $r_i = (60, 61, 62, . . . , 78, 79, 80)mm$\n",
    "2. $r_o$ the outer radius in . $r_o = (90, 91, 92, . . . , 108, 109, 110)mm$\n",
    "3. $t$ the tickness of discs in mm. $t = (1, 1.5, 2, 2.5, 3)mm$\n",
    "4. $F$ the actuating force in N(Newton). $F = (600, 610, 620, . . . , 980, 990, 1000)N$\n",
    "5. $Z$ the number of discs. $Z = (2, 3, 4, 5, 6, 7, 8, 10)$\n",
    "\n",
    "**For each of the exercises, perform multiple runs (with different random seeds) to reduce the effect of randomness on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11mcwlyXuGjQ"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ko3ZWvfvJW8"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from copy import copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional\n",
    "\n",
    "import inspyred.ec.emo as emo\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from inspyred.benchmarks import Benchmark, Kursawe\n",
    "from inspyred.ec import (\n",
    "    EvolutionaryComputation,\n",
    "    Individual,\n",
    "    replacers,\n",
    "    selectors,\n",
    "    terminators,\n",
    "    variators,\n",
    ")\n",
    "from inspyred.ec.variators import mutator\n",
    "from numpy.random import RandomState\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XQq5M4L8uQ-f"
   },
   "outputs": [],
   "source": [
    "# @markdown Implementation of benchmarks and utilites (double click to open)\n",
    "class NumpyRandomWrapper(RandomState):\n",
    "    def __init__(self, seed: Optional[int] = None) -> None:\n",
    "        super(NumpyRandomWrapper, self).__init__(seed)\n",
    "\n",
    "    def sample(\n",
    "        self, pop: int | list[float] | NDArray[pl.float64], k: int\n",
    "    ) -> NDArray[pl.float64]:\n",
    "        population: list[int | float] | NDArray[pl.float64]\n",
    "        if isinstance(pop, int):\n",
    "            population = list(range(pop))\n",
    "        else:\n",
    "            population = pop\n",
    "\n",
    "        return pl.asarray(\n",
    "            [\n",
    "                population[i]\n",
    "                for i in self._choice_without_replacement(len(population), k)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def random(self) -> float:  # type: ignore\n",
    "        return self.random_sample()\n",
    "\n",
    "    def gauss(self, mu: float, sigma: float) -> float:\n",
    "        return self.normal(mu, sigma)\n",
    "\n",
    "    def _choice_without_replacement(self, n: int, size: int) -> set[int]:\n",
    "        result: set[int] = set()\n",
    "        while len(result) < size:\n",
    "            result.add(self.randint(0, n))\n",
    "        return result\n",
    "\n",
    "\n",
    "def initial_pop_observer(\n",
    "    population: list[Individual],\n",
    "    num_generations: int,\n",
    "    num_evaluations: int,\n",
    "    args: dict[str, Any],\n",
    ") -> None:\n",
    "    if num_generations == 0:\n",
    "        args[\"initial_pop_storage\"][\"individuals\"] = pl.asarray(\n",
    "            [guy.candidate for guy in population]\n",
    "        )\n",
    "        args[\"initial_pop_storage\"][\"fitnesses\"] = pl.asarray(\n",
    "            [guy.fitness for guy in population]\n",
    "        )\n",
    "\n",
    "\n",
    "def generator(random: NumpyRandomWrapper, args: Any) -> NDArray[pl.float64]:\n",
    "    return pl.asarray(\n",
    "        [\n",
    "            random.uniform(args[\"pop_init_range\"][0], args[\"pop_init_range\"][1])\n",
    "            for _ in range(args[\"num_vars\"])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def generator_wrapper(func: Any) -> Any:\n",
    "    @functools.wraps(func)\n",
    "    def _generator(random: NumpyRandomWrapper, args: Any) -> NDArray[pl.float64]:\n",
    "        return pl.asarray(func(random, args))\n",
    "\n",
    "    return _generator\n",
    "\n",
    "\n",
    "class CombinedObjectives(emo.Pareto):\n",
    "    def __init__(self, pareto: emo.Pareto, args: dict[str, Any]) -> None:\n",
    "        \"\"\"edit this function to change the way that multiple objectives\n",
    "        are combined into a single objective\n",
    "\n",
    "        \"\"\"\n",
    "        emo.Pareto.__init__(self, pareto.values)\n",
    "        weights: NDArray[pl.float64]\n",
    "        if \"fitness_weights\" in args:\n",
    "            weights = pl.asarray(args[\"fitness_weights\"])\n",
    "        else:\n",
    "            weights = pl.asarray([1.0 for _ in pareto.values])\n",
    "\n",
    "        self.fitness = sum(pl.asarray(pareto.values) * weights)\n",
    "\n",
    "    def __lt__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, CombinedObjectives):\n",
    "            raise ValueError(\"Cannot compare CombinedObjectives with other types\")\n",
    "        return self.fitness < other.fitness\n",
    "\n",
    "\n",
    "def single_objective_evaluator(\n",
    "    candidates: list[Individual], args: dict[str, Any]\n",
    ") -> list[CombinedObjectives]:\n",
    "    problem: Benchmark = args[\"problem\"]\n",
    "    return [\n",
    "        CombinedObjectives(fit, args) for fit in problem.evaluator(candidates, args)\n",
    "    ]\n",
    "\n",
    "\n",
    "# parameters, see Deb 2006\n",
    "Delta_R = 20  # mm\n",
    "L_max = 30  # mm\n",
    "delta = 0.5  # mm\n",
    "p_max = 1  # MPa\n",
    "V_sr_max = 10  # m/s\n",
    "n = 250  # rpm\n",
    "mu = 0.5\n",
    "s = 1.5\n",
    "M_s = 40  # Nm\n",
    "omega = pl.pi * n / 30.0  # rad/s\n",
    "rho = 0.0000078  # kg/mm^3\n",
    "T_max = 15  # s\n",
    "M_f = 3  # Nm\n",
    "I_z = 55  # kg*m^2\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateDiskClutchBrake:\n",
    "    inner_radius: int\n",
    "    outer_radius: int\n",
    "    thickness: float\n",
    "    force: int\n",
    "    number_of_disks: int\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(\n",
    "            [\n",
    "                self.inner_radius,\n",
    "                self.outer_radius,\n",
    "                self.thickness,\n",
    "                self.force,\n",
    "                self.number_of_disks,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return [\n",
    "            self.inner_radius,\n",
    "            self.outer_radius,\n",
    "            self.thickness,\n",
    "            self.force,\n",
    "            self.number_of_disks,\n",
    "        ][index]\n",
    "\n",
    "    def __setitem__(self, index: int, value: float):\n",
    "        if index == 0:\n",
    "            self.inner_radius = int(value)\n",
    "        elif index == 1:\n",
    "            self.outer_radius = int(value)\n",
    "        elif index == 2:\n",
    "            self.thickness = value\n",
    "        elif index == 3:\n",
    "            self.force = int(value)\n",
    "        elif index == 4:\n",
    "            self.number_of_disks = int(value)\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 5\n",
    "\n",
    "    @property\n",
    "    def bounds(self):\n",
    "        return [\n",
    "            pl.arange(60, 81, 1),\n",
    "            pl.arange(90, 111, 1),\n",
    "            pl.arange(1.5, 3.5, 0.5),\n",
    "            pl.arange(600, 1010, 10),\n",
    "            pl.arange(2, 10, 1),\n",
    "        ]\n",
    "\n",
    "\n",
    "# possible values\n",
    "VALUES: list[NDArray[pl.float64]] = [\n",
    "    pl.arange(60, 81, 1.0),\n",
    "    pl.arange(90, 111, 1.0),\n",
    "    pl.arange(1.5, 3.5, 0.5),\n",
    "    pl.arange(600, 1010, 10.0),\n",
    "    pl.arange(2, 10, 1.0),\n",
    "]\n",
    "\n",
    "\n",
    "class DiskClutchBounder(object):\n",
    "    def __call__(\n",
    "        self, candidate: NDArray[pl.float64], args: dict[str, Any]\n",
    "    ) -> NDArray[pl.float64]:\n",
    "        for i, c in enumerate(candidate):\n",
    "            candidate[i] = self._closest(c, i)\n",
    "        return candidate\n",
    "\n",
    "    def _closest(self, target: float, index: int) -> float:\n",
    "        return min(VALUES[index], key=lambda x: abs(x - target))\n",
    "\n",
    "\n",
    "class ConstrainedPareto(emo.Pareto):\n",
    "    def __init__(\n",
    "        self,\n",
    "        values: Optional[list[float]] = None,\n",
    "        violations: Optional[int] = None,\n",
    "        ec_maximize: bool = True,\n",
    "    ):\n",
    "        emo.Pareto.__init__(self, values)\n",
    "        self.violations = violations\n",
    "        self.ec_maximize = ec_maximize\n",
    "\n",
    "    def __lt__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, ConstrainedPareto):\n",
    "            raise ValueError(\"Cannot compare CombinedObjectives with other types\")\n",
    "\n",
    "        if self.violations is None:\n",
    "            return emo.Pareto.__lt__(self, other)\n",
    "        elif len(self.values) != len(other.values):\n",
    "            raise ValueError(\"Cannot compare Pareto fronts with different lengths\")\n",
    "        else:\n",
    "            if other.violations is not None and self.violations > other.violations:\n",
    "                # if self has more violations than other\n",
    "                # return true if EC is maximizing otherwise false\n",
    "                return self.ec_maximize\n",
    "            elif other.violations is not None and other.violations > self.violations:\n",
    "                # if other has more violations than self\n",
    "                # return true if EC is minimizing otherwise false\n",
    "                return not self.ec_maximize\n",
    "            elif self.violations > 0:\n",
    "                # if both equally infeasible (> 0) than cannot compare\n",
    "                return False\n",
    "            else:\n",
    "                # only consider regular dominance if both are feasible\n",
    "                not_worse = True\n",
    "                strictly_better = False\n",
    "                if isinstance(self.maximize, list):\n",
    "                    for x, y, m in zip(self.values, other.values, self.maximize):\n",
    "                        if m:\n",
    "                            if x > y:\n",
    "                                not_worse = False\n",
    "                            elif y > x:\n",
    "                                strictly_better = True\n",
    "                        else:\n",
    "                            if x < y:\n",
    "                                not_worse = False\n",
    "                            elif y < x:\n",
    "                                strictly_better = True\n",
    "                else:\n",
    "                    raise ValueError(\"maximize must be a list\")\n",
    "            return not_worse and strictly_better\n",
    "\n",
    "\n",
    "class DiskClutchBrake(Benchmark):\n",
    "    def __init__(self, constrained: bool = False) -> None:\n",
    "        Benchmark.__init__(self, 5, 2)\n",
    "        self.bounder = DiskClutchBounder()\n",
    "        self.maximize = False\n",
    "        self.constrained = constrained\n",
    "\n",
    "    def generator(\n",
    "        self, random: NumpyRandomWrapper, args: dict[str, Any]\n",
    "    ) -> list[NDArray[pl.float64]]:\n",
    "        return [random.sample(VALUES[i], 1)[0] for i in range(self.dimensions)]\n",
    "\n",
    "    def evaluator(self, candidates: list[NDArray[pl.float64]], args: dict[str, Any]):\n",
    "        fitness: list[ConstrainedPareto] = []\n",
    "        for c in candidates:\n",
    "            f1 = pl.pi * (c[1] ** 2 - c[0] ** 2) * c[2] * (c[4] + 1) * rho\n",
    "\n",
    "            M_h = (\n",
    "                (2.0 / 3.0)\n",
    "                * mu\n",
    "                * c[3]\n",
    "                * c[4]\n",
    "                * (c[1] ** 3 - c[0] ** 3)\n",
    "                / (c[1] ** 2 - c[0] ** 2)\n",
    "            ) / 1000.0  # N*m\n",
    "            T = (I_z * omega) / (M_h + M_f)\n",
    "\n",
    "            f2 = T\n",
    "\n",
    "            fitness.append(\n",
    "                ConstrainedPareto([f1, f2], self.constraint_function(c), self.maximize)\n",
    "            )\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    def constraint_function(self, candidate: NDArray[pl.float64]) -> int:\n",
    "        if not self.constrained:\n",
    "            return 0\n",
    "        \"\"\"Return the magnitude of constraint violations.\"\"\"\n",
    "        A = pl.pi * (candidate[1] ** 2 - candidate[0] ** 2)  # mm^2\n",
    "        p_rz = candidate[3] / A  # N/mm^2\n",
    "        R_sr = (\n",
    "            (2.0 / 3.0)\n",
    "            * (candidate[1] ** 3 - candidate[0] ** 3)\n",
    "            / (candidate[1] ** 2 - candidate[0] ** 2)\n",
    "        )  # mm\n",
    "        V_sr = pl.pi * R_sr * n / 30000.0  # m/s\n",
    "\n",
    "        M_h = (\n",
    "            (2.0 / 3.0)\n",
    "            * mu\n",
    "            * candidate[3]\n",
    "            * candidate[4]\n",
    "            * (candidate[1] ** 3 - candidate[0] ** 3)\n",
    "            / (candidate[1] ** 2 - candidate[0] ** 2)\n",
    "        ) / 1000.0  # N*m\n",
    "\n",
    "        T = (I_z * omega) / (M_h + M_f)\n",
    "\n",
    "        violations: int = 0\n",
    "        # g_1\n",
    "        if (candidate[1] - candidate[0] - Delta_R) < 0:\n",
    "            violations -= candidate[1] - candidate[0] - Delta_R\n",
    "        # g_2\n",
    "        if (L_max - (candidate[4] + 1) * (candidate[2] + delta)) < 0:\n",
    "            violations -= L_max - (candidate[4] + 1) * (candidate[2] + delta)\n",
    "        # g_3\n",
    "        if (p_max - p_rz) < 0:\n",
    "            violations -= p_max - p_rz\n",
    "        # g_4\n",
    "        if (p_max * V_sr_max - p_rz * V_sr) < 0:\n",
    "            violations -= p_max * V_sr_max - p_rz * V_sr\n",
    "        # g_5\n",
    "        if (V_sr_max - V_sr) < 0:\n",
    "            violations -= V_sr_max - V_sr\n",
    "        # g_6\n",
    "        if (M_h - s * M_s) < 0:\n",
    "            violations -= M_h - s * M_s\n",
    "        # g_7\n",
    "        if T < 0:\n",
    "            violations -= T\n",
    "        # g_8\n",
    "        if (T_max - T) < 0:\n",
    "            violations -= T_max - T\n",
    "\n",
    "        return violations\n",
    "\n",
    "\n",
    "@mutator\n",
    "def disk_clutch_brake_mutation(\n",
    "    random: NumpyRandomWrapper, candidate: NDArray[pl.float64], args: dict[str, Any]\n",
    ") -> NDArray[pl.float64]:\n",
    "    mut_rate = args.setdefault(\"mutation_rate\", 0.1)\n",
    "    bounder: DiskClutchBounder = args[\"_ec\"].bounder\n",
    "    mutant = copy(candidate)\n",
    "    for i, _ in enumerate(mutant):\n",
    "        if random.random() < mut_rate:\n",
    "            mutant[i] += random.gauss(0, (VALUES[i][-1] - VALUES[i][0]) / 10.0)\n",
    "    mutant = bounder(mutant, args)\n",
    "    return mutant\n",
    "\n",
    "\n",
    "class NSGA2(emo.NSGA2):\n",
    "    def __init__(self, random: NumpyRandomWrapper) -> None:\n",
    "        emo.NSGA2.__init__(self, random)\n",
    "        self.population_archive: list[list[Individual]] = []\n",
    "\n",
    "    # helper function used to store the various populations at each generation\n",
    "    def _best_archiver(\n",
    "        self,\n",
    "        random: NumpyRandomWrapper,\n",
    "        population: list[Individual],\n",
    "        archive: list[Individual],\n",
    "        args: dict[str, Any],\n",
    "    ) -> list[Individual]:\n",
    "        self.population_archive.append(population)\n",
    "        new_archive = archive\n",
    "        for ind in population:\n",
    "            if len(new_archive) == 0:\n",
    "                new_archive.append(ind)\n",
    "            else:\n",
    "                should_remove = []\n",
    "                should_add = True\n",
    "                for a in new_archive:\n",
    "                    if (pl.array(ind.candidate) == pl.array(a.candidate)).all():\n",
    "                        should_add = False\n",
    "                        break\n",
    "                    elif ind < a:\n",
    "                        should_add = False\n",
    "                    elif ind > a:\n",
    "                        should_remove.append(a)\n",
    "                for r in should_remove:\n",
    "                    new_archive.remove(r)\n",
    "                if should_add:\n",
    "                    new_archive.append(ind)\n",
    "        return new_archive\n",
    "\n",
    "    def run_nsga2(\n",
    "        self,\n",
    "        problem: Benchmark,\n",
    "        display: bool = False,\n",
    "        num_vars: int = 0,\n",
    "        use_bounder: bool = True,\n",
    "        variator: Optional[Any] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> tuple[NDArray[pl.float64], NDArray[pl.float64], list[NDArray[pl.float64]]]:\n",
    "        \"\"\"run NSGA2 on the given problem\"\"\"\n",
    "\n",
    "        # create dictionaries to store data about initial population, and lines\n",
    "        initial_pop_storage: dict[str, Any] = {}\n",
    "\n",
    "        self.archiver = self._best_archiver\n",
    "        self.terminator = terminators.generation_termination\n",
    "        if variator is None:\n",
    "            self.variator = [variators.blend_crossover, variators.gaussian_mutation]\n",
    "        else:\n",
    "            self.variator = variator\n",
    "\n",
    "        kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "        if use_bounder:\n",
    "            kwargs[\"bounder\"] = problem.bounder\n",
    "\n",
    "        if \"pop_init_range\" in kwargs:\n",
    "            kwargs[\"generator\"] = generator\n",
    "        else:\n",
    "            kwargs[\"generator\"] = problem.generator\n",
    "        final_pop: list[Individual] = self.evolve(\n",
    "            evaluator=problem.evaluator,\n",
    "            maximize=problem.maximize,\n",
    "            initial_pop_storage=initial_pop_storage,\n",
    "            num_vars=num_vars,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # assert isinstance(final_pop, list)\n",
    "        all_populations = self.population_archive\n",
    "        all_populations_fitnesses: list[NDArray[pl.float64]] = [\n",
    "            pl.asarray([guy.fitness for guy in pop]) for pop in all_populations\n",
    "        ]\n",
    "\n",
    "        # best_guy = final_pop[0].candidate[0:num_vars] # type: ignore\n",
    "        # best_fitness: float = final_pop[0].fitness\n",
    "        final_pop_fitnesses: NDArray[pl.float64] = pl.asarray(\n",
    "            [guy.fitness for guy in final_pop]\n",
    "        )\n",
    "        final_pop_candidates: NDArray[pl.float64] = pl.asarray([guy.candidate[0:num_vars] for guy in final_pop])  # type: ignore\n",
    "\n",
    "        return final_pop_candidates, final_pop_fitnesses, all_populations_fitnesses\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    random: NumpyRandomWrapper,\n",
    "    problem: Benchmark,\n",
    "    display: bool = False,\n",
    "    num_vars: int = 0,\n",
    "    maximize: bool = False,\n",
    "    use_bounder: bool = True,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[NDArray[pl.float64], float]:\n",
    "    \"\"\"run a GA on the given problem\"\"\"\n",
    "\n",
    "    # create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage: dict[str, Any] = {}\n",
    "\n",
    "    algorithm = EvolutionaryComputation(random)\n",
    "    algorithm.terminator = terminators.generation_termination\n",
    "    algorithm.replacer = replacers.generational_replacement\n",
    "    algorithm.variator = [variators.uniform_crossover, variators.gaussian_mutation]  # type: ignore\n",
    "    algorithm.selector = selectors.tournament_selection\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "    if use_bounder:\n",
    "        kwargs[\"bounder\"] = problem.bounder\n",
    "    if \"pop_init_range\" in kwargs:\n",
    "        kwargs[\"generator\"] = generator\n",
    "    else:\n",
    "        kwargs[\"generator\"] = problem.generator\n",
    "\n",
    "    kwargs[\"problem\"] = problem\n",
    "    final_pop: list[Individual] = algorithm.evolve(\n",
    "        evaluator=single_objective_evaluator,\n",
    "        maximize=problem.maximize,\n",
    "        initial_pop_storage=initial_pop_storage,\n",
    "        num_vars=num_vars,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    best_guy: NDArray[pl.float64] = final_pop[0].candidate  # type: ignore\n",
    "    best_fitness: float = final_pop[0].fitness  # type: ignore\n",
    "    final_pop_fitnesses: NDArray[pl.float64] = pl.asarray(\n",
    "        [guy.fitness for guy in final_pop]\n",
    "    )\n",
    "    # final_pop_candidates: NDArray[pl.float64] = pl.asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    if display:\n",
    "        # print(\"Candidates: \", final_pop_candidates.shape)\n",
    "        # print(\"Fitnesses: \", final_pop_fitnesses.shape)\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "        ax.plot(final_pop_fitnesses.T[0], final_pop_fitnesses.T[1], \"ro\")\n",
    "        ax.set_xlabel(\"f1\")\n",
    "        ax.set_ylabel(\"f2\")\n",
    "        ax.set_title(\"Final population\")\n",
    "        # plot candidates as heatmap\n",
    "        # ax[1].hist2d(final_pop_candidates.T[0], final_pop_candidates.T[1], bins=50)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return best_guy, best_fitness\n",
    "\n",
    "\n",
    "def plot_pareto(\n",
    "    final_pop_fitnesses: NDArray[pl.float64],\n",
    "    function_labels: Optional[tuple[str, str]] = None,\n",
    ") -> None:\n",
    "    plt.scatter(\n",
    "        final_pop_fitnesses.T[0],\n",
    "        final_pop_fitnesses.T[1],\n",
    "        color=\"red\",\n",
    "        label=\"Pareto front\",\n",
    "    )\n",
    "\n",
    "    if not function_labels:\n",
    "        plt.xlabel(\"f1\")\n",
    "        plt.ylabel(\"f2\")\n",
    "    else:\n",
    "        plt.xlabel(function_labels[0])\n",
    "        plt.ylabel(function_labels[1])\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pareto_rank(\n",
    "    all_populations: list[NDArray[pl.float64]],\n",
    "    function_labels: Optional[tuple[str, str]] = None,\n",
    ") -> None:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(7)\n",
    "\n",
    "    pareto_front = all_populations[-1]\n",
    "    ax.scatter(pareto_front.T[0], pareto_front.T[1], color=\"red\", label=\"Pareto front\")\n",
    "\n",
    "    for i in range(min(len(all_populations), 5)):\n",
    "        ax.scatter(\n",
    "            all_populations[i].T[0],\n",
    "            all_populations[i].T[1],\n",
    "            label=(\"Front \" + str(i + 1)),\n",
    "        )\n",
    "\n",
    "    if not function_labels:\n",
    "        ax.set_xlabel(\"f1\")\n",
    "        ax.set_ylabel(\"f2\")\n",
    "    else:\n",
    "        ax.set_xlabel(function_labels[0])\n",
    "        ax.set_ylabel(function_labels[1])\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_pareto_front_statistics(\n",
    "    final_pop_candidates: NDArray[pl.float64],\n",
    "    final_pop_fitnesses: NDArray[pl.float64],\n",
    "    num_objectives: int,\n",
    ") -> list[tuple[NDArray[pl.float64], NDArray[pl.float64]]]:\n",
    "    results: list[tuple[NDArray[pl.float64], NDArray[pl.float64]]] = []\n",
    "    for i in range(num_objectives):\n",
    "        # candidates that minimize f_i\n",
    "        f_min_index = final_pop_fitnesses.T[i].argmin()\n",
    "        f_min_candidate = final_pop_candidates[f_min_index]\n",
    "        f_min_fitness = final_pop_fitnesses[f_min_index]\n",
    "        results.append((f_min_candidate, f_min_fitness))\n",
    "\n",
    "    # fitness closest to the origin\n",
    "    origin_distance = pl.sqrt(pl.sum(final_pop_fitnesses**2, axis=1))\n",
    "    closest_index = origin_distance.argmin()\n",
    "    closest_candidate = final_pop_candidates[closest_index]\n",
    "    closest_fitness = final_pop_fitnesses[closest_index]\n",
    "    results.append((closest_candidate, closest_fitness))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOi-e1R5vPGB"
   },
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Dz99sJ7vSM8"
   },
   "source": [
    "#### Exercise 1/2: Kursawe's function\n",
    "\n",
    "1. Weighted sum of the objectives: what's the influence of the weights on the output of the search process?\n",
    "2. Using NSGA-II, plot the Pareto front of the solutions obtained during the optimization process.\n",
    "3. Compare the weighted-sum method with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GA on the Kursawe problem with different fitness weights\n",
    "problem = Kursawe(3)\n",
    "\n",
    "# Parameters for the GA\n",
    "args: dict[str, Any] = {}\n",
    "fitness_weights = [[1, 0], [0, 1], [0.5, 0.5], [0.3, 0.7], [0.7, 0.3]]\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 100\n",
    "args[\"fitness_weights\"] = [1, 1]\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int]\n",
    "overall_best: Optional[float]\n",
    "best_fitnesses: list[float]\n",
    "\n",
    "\n",
    "for weights in fitness_weights:\n",
    "    args[\"fitness_weights\"] = weights\n",
    "    best_seed = None\n",
    "    overall_best = None\n",
    "    best_fitnesses = []\n",
    "    for sim in range(num_simulations):\n",
    "        seed = sim * 17 + 51\n",
    "        # Initialize a random number generator with a seed\n",
    "        rng = NumpyRandomWrapper(sim * 17 + 51)\n",
    "        # Run the GA\n",
    "        best_guy, best_fitness = run_ga(rng, problem, num_vars=3, display=False, **args)\n",
    "        best_fitnesses.append(best_fitness)\n",
    "        if best_seed is None or overall_best is None or best_fitness < overall_best:\n",
    "            best_seed = seed\n",
    "            overall_best = best_fitness\n",
    "\n",
    "    rng = NumpyRandomWrapper(best_seed)\n",
    "    # Run the GA\n",
    "    best_guy, best_fitness = run_ga(\n",
    "        rng, problem, num_vars=3, display=True, maximize=False, **args\n",
    "    )\n",
    "    print(\"Fitness weights: \", weights)\n",
    "    print(\"Best solution: \", best_guy)\n",
    "    print(\"Best fitness: \", best_fitness)\n",
    "    # Print the mean and standard deviation of the best fitness\n",
    "    print(\"Mean fitness: \", pl.mean(best_fitnesses, axis=0))\n",
    "    print(\"Standard deviation of fitness: \", pl.std(best_fitnesses, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NSGA2 on the Kursawe problem\n",
    "problem = Kursawe(3)\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int] = None\n",
    "overall_best: Optional[float] = None\n",
    "best_f1_fitness: list[float] = []\n",
    "best_f2_fitness: list[float] = []\n",
    "best_origin_fitness: list[float] = []\n",
    "\n",
    "for sim in range(num_simulations):\n",
    "    seed = sim * 17 + 51\n",
    "    # Initialize a random number generator with a seed\n",
    "    rng = NumpyRandomWrapper(seed)\n",
    "    nsga2 = NSGA2(rng)\n",
    "    # Run the NSGA2\n",
    "    (\n",
    "        final_pop_candidates,\n",
    "        final_pop_fitnesses,\n",
    "        all_populations_fitnesses,\n",
    "    ) = nsga2.run_nsga2(problem, num_vars=3, **args)\n",
    "    # Compute the statistics of the Pareto front\n",
    "    results = compute_pareto_front_statistics(\n",
    "        final_pop_candidates, final_pop_fitnesses, 2\n",
    "    )\n",
    "    best_f1_fitness.append(results[0][1].item())\n",
    "    best_f2_fitness.append(results[1][1].item())\n",
    "    best_origin_fitness.append(results[2][1].item())\n",
    "\n",
    "    if best_seed is None or overall_best is None or results[2][1][0] < overall_best:\n",
    "        best_seed = seed\n",
    "        overall_best = results[2][1][0]\n",
    "\n",
    "    # Print the results\n",
    "    # print(f\"Best solution for objective f1 for iteration {sim}: \", results[0][0])\n",
    "    # print(f\"Best fitness for objective f1 for iteration {sim}: \", results[0][1])\n",
    "    # print(f\"Best solution for objective f2 for iteration {sim}: \", results[1][0])\n",
    "    # print(f\"Best fitness for objective f2 for iteration {sim}: \", results[1][1])\n",
    "    # print(f\"Best solution closest to the origin for iteration {sim}: \", results[2][0])\n",
    "    # print(f\"Best fitness closest to the origin for iteration {sim}: \", results[2][1])\n",
    "\n",
    "# Print the mean and standard deviation of the best fitness\n",
    "print(\"Mean fitness for f1: \", pl.mean(best_f1_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f1: \", pl.std(best_f1_fitness, axis=0))\n",
    "print(\"Mean fitness for f2: \", pl.mean(best_f2_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f2: \", pl.std(best_f2_fitness, axis=0))\n",
    "print(\"Mean fitness closest ti origin: \", pl.mean(best_origin_fitness, axis=0))\n",
    "print(\"Standard deviation closest to fitness: \", pl.std(best_origin_fitness, axis=0))\n",
    "\n",
    "nsga2 = NSGA2(NumpyRandomWrapper(best_seed))\n",
    "final_pop_candidates, final_pop_fitnesses, all_populations_fitnesses = nsga2.run_nsga2(\n",
    "    problem, num_vars=3, **args\n",
    ")\n",
    "# print(\"Best solutions: \", final_pop_candidates)\n",
    "# print(\"Best fitnesses: \", final_pop_fitnesses)\n",
    "\n",
    "plot_pareto(final_pop_fitnesses, (\"f1\", \"f2\"))\n",
    "plot_pareto_rank(all_populations_fitnesses, (\"f1\", \"f2\"))\n",
    "results = compute_pareto_front_statistics(final_pop_candidates, final_pop_fitnesses, 2)\n",
    "print(\n",
    "    f\"Best solution for objective f1 with {num_simulations} simulations: \",\n",
    "    results[0][0],\n",
    ")\n",
    "print(\n",
    "    f\"Best fitness for objective f1 with {num_simulations} simulations: \", results[0][1]\n",
    ")\n",
    "print(\n",
    "    f\"Best solution for objective f2 with {num_simulations} simulations: \",\n",
    "    results[1][0],\n",
    ")\n",
    "print(\n",
    "    f\"Best fitness for objective f2 with {num_simulations} simulations: \", results[1][1]\n",
    ")\n",
    "print(\n",
    "    f\"Best solution closest to the origin with {num_simulations} simulations: \",\n",
    "    results[2][0],\n",
    ")\n",
    "print(\n",
    "    f\"Best fitness closest to the origin with {num_simulations} simulations: \",\n",
    "    results[2][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skFzrMTIwCV-"
   },
   "source": [
    "#### Exercise 2/2: Multi-disk clutch brake optimization\n",
    "\n",
    "1. Weighted sum of the objectives: what's the influence of the weights on the output of the search process?\n",
    "2. Using NSGA-II, plot the Pareto front of the solutions obtained during the optimization process.\n",
    "3. Compare the weighted-sum method with NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GA on the disk clutch brake problem\n",
    "problem = DiskClutchBrake(False)\n",
    "\n",
    "# Parameters for the GA\n",
    "args: dict[str, Any] = {}\n",
    "fitness_weights = [[1, 0], [0, 1], [1, 1], [1, 2], [2, 1]]\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int] = None\n",
    "overall_best: Optional[float] = None\n",
    "best_fitnesses: list[float] = []\n",
    "\n",
    "\n",
    "for weights in fitness_weights:\n",
    "    args[\"fitness_weights\"] = weights\n",
    "    best_seed = None\n",
    "    overall_best = None\n",
    "    best_fitnesses = []\n",
    "    for sim in range(num_simulations):\n",
    "        seed = sim * 17 + 51\n",
    "        # Initialize a random number generator with a seed\n",
    "        rng = NumpyRandomWrapper(sim * 17 + 51)\n",
    "        # Run the GA\n",
    "        best_guy, best_fitness = run_ga(rng, problem, num_vars=3, display=False, **args)\n",
    "        best_fitnesses.append(best_fitness)\n",
    "        if best_seed is None or overall_best is None or best_fitness < overall_best:\n",
    "            best_seed = seed\n",
    "            overall_best = best_fitness\n",
    "\n",
    "    rng = NumpyRandomWrapper(best_seed)\n",
    "    # Run the GA\n",
    "    best_guy, best_fitness = run_ga(\n",
    "        rng, problem, num_vars=3, display=True, maximize=False, **args\n",
    "    )\n",
    "    print(\"Fitness weights: \", weights)\n",
    "    print(\"Best solution: \", best_guy)\n",
    "    print(\"Best fitness: \", best_fitness)\n",
    "    # Print the mean and standard deviation of the best fitness\n",
    "    print(\"Mean fitness: \", pl.mean(best_fitnesses, axis=0))\n",
    "    print(\"Standard deviation of fitness: \", pl.std(best_fitnesses, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDGzxbtAv1aM"
   },
   "outputs": [],
   "source": [
    "# parameters for NSGA-2\n",
    "args: dict[str, Any] = {}\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "problem = DiskClutchBrake(False)\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int] = None\n",
    "overall_best: Optional[float] = None\n",
    "best_f1_fitness: list[float] = []\n",
    "best_f2_fitness: list[float] = []\n",
    "best_origin_fitness: list[float] = []\n",
    "\n",
    "for sim in range(num_simulations):\n",
    "    seed = sim * 17 + 51\n",
    "    # Initialize a random number generator with a seed\n",
    "    rng = NumpyRandomWrapper(seed)\n",
    "    nsga2 = NSGA2(rng)\n",
    "    # Run the NSGA2\n",
    "    (\n",
    "        final_pop_candidates,\n",
    "        final_pop_fitnesses,\n",
    "        all_populations_fitnesses,\n",
    "    ) = nsga2.run_nsga2(problem, num_vars=3, **args)\n",
    "    # Compute the statistics of the Pareto front\n",
    "    results = compute_pareto_front_statistics(\n",
    "        final_pop_candidates, final_pop_fitnesses, 2\n",
    "    )\n",
    "    best_f1_fitness.append(results[0][1].item())\n",
    "    best_f2_fitness.append(results[1][1].item())\n",
    "    best_origin_fitness.append(results[2][1].item())\n",
    "\n",
    "    if best_seed is None or overall_best is None or results[2][1][0] < overall_best:\n",
    "        best_seed = seed\n",
    "        overall_best = results[2][1][0]\n",
    "\n",
    "    # Print the results\n",
    "    # print(f\"Best solution for objective f1 for iteration {sim}: \", results[0][0])\n",
    "    # print(f\"Best fitness for objective f1 for iteration {sim}: \", results[0][1])\n",
    "    # print(f\"Best solution for objective f2 for iteration {sim}: \", results[1][0])\n",
    "    # print(f\"Best fitness for objective f2 for iteration {sim}: \", results[1][1])\n",
    "    # print(f\"Best solution closest to the origin for iteration {sim}: \", results[2][0])\n",
    "    # print(f\"Best fitness closest to the origin for iteration {sim}: \", results[2][1])\n",
    "\n",
    "# Print the mean and standard deviation of the best fitness\n",
    "print(\"Mean fitness for f1: \", pl.mean(best_f1_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f1: \", pl.std(best_f1_fitness, axis=0))\n",
    "print(\"Mean fitness for f2: \", pl.mean(best_f2_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f2: \", pl.std(best_f2_fitness, axis=0))\n",
    "print(\"Mean fitness closest ti origin: \", pl.mean(best_origin_fitness, axis=0))\n",
    "print(\"Standard deviation closest to fitness: \", pl.std(best_origin_fitness, axis=0))\n",
    "\n",
    "nsga2 = NSGA2(NumpyRandomWrapper(best_seed))\n",
    "final_pop_candidates, final_pop_fitnesses, all_populations_fitnesses = nsga2.run_nsga2(\n",
    "    problem, num_vars=3, **args\n",
    ")\n",
    "# print(\"Best solutions: \", final_pop_candidates)\n",
    "# print(\"Best fitnesses: \", final_pop_fitnesses)\n",
    "\n",
    "plot_pareto(final_pop_fitnesses, (\"f1\", \"f2\"))\n",
    "plot_pareto_rank(all_populations_fitnesses, (\"f1\", \"f2\"))\n",
    "results = compute_pareto_front_statistics(final_pop_candidates, final_pop_fitnesses, 2)\n",
    "print(f\"Best solution for objective f1 for iteration {sim}: \", results[0][0])\n",
    "print(f\"Best fitness for objective f1 for iteration {sim}: \", results[0][1])\n",
    "print(f\"Best solution for objective f2 for iteration {sim}: \", results[1][0])\n",
    "print(f\"Best fitness for objective f2 for iteration {sim}: \", results[1][1])\n",
    "print(f\"Best solution closest to the origin for iteration {sim}: \", results[2][0])\n",
    "print(f\"Best fitness closest to the origin for iteration {sim}: \", results[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GA on the Disk Clutch Brake problem with different fitness weights\n",
    "problem = DiskClutchBrake(True)\n",
    "\n",
    "# Parameters for the GA\n",
    "args: dict[str, Any] = {}\n",
    "fitness_weights = [[1, 0], [0, 1], [1, 1], [1, 2], [2, 1]]\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int]\n",
    "overall_best: Optional[float]\n",
    "best_fitnesses: list[float]\n",
    "\n",
    "\n",
    "for weights in fitness_weights:\n",
    "    args[\"fitness_weights\"] = weights\n",
    "    best_seed = None\n",
    "    overall_best = None\n",
    "    best_fitnesses = []\n",
    "    for sim in range(num_simulations):\n",
    "        seed = sim * 17 + 51\n",
    "        # Initialize a random number generator with a seed\n",
    "        rng = NumpyRandomWrapper(sim * 17 + 51)\n",
    "        # Run the GA\n",
    "        best_guy, best_fitness = run_ga(\n",
    "            rng, problem, num_vars=3, display=False, maximize=False, **args\n",
    "        )\n",
    "        best_fitnesses.append(best_fitness)\n",
    "        if best_seed is None or overall_best is None or best_fitness < overall_best:\n",
    "            best_seed = seed\n",
    "            overall_best = best_fitness\n",
    "\n",
    "    rng = NumpyRandomWrapper(best_seed)\n",
    "    # Run the GA\n",
    "    best_guy, best_fitness = run_ga(\n",
    "        rng, problem, num_vars=3, display=True, maximize=False, **args\n",
    "    )\n",
    "    print(\"Fitness weights: \", weights)\n",
    "    print(\"Best solution: \", best_guy)\n",
    "    print(\"Best fitness: \", best_fitness)\n",
    "    # Print the mean and standard deviation of the best fitness\n",
    "    print(\"Mean fitness: \", pl.mean(best_fitnesses, axis=0))\n",
    "    print(\"Standard deviation of fitness: \", pl.std(best_fitnesses, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrained problem NSGA-2\n",
    "args: dict[str, Any] = {}\n",
    "args[\"pop_size\"] = 50\n",
    "args[\"max_generations\"] = 50\n",
    "args[\"variator\"] = [variators.blend_crossover, disk_clutch_brake_mutation]\n",
    "problem = DiskClutchBrake(True)\n",
    "\n",
    "num_simulations = 50\n",
    "best_seed: Optional[int] = None\n",
    "overall_best: Optional[float] = None\n",
    "best_f1_fitness: list[float] = []\n",
    "best_f2_fitness: list[float] = []\n",
    "best_origin_fitness: list[float] = []\n",
    "\n",
    "for sim in range(num_simulations):\n",
    "    seed = sim * 17 + 51\n",
    "    # Initialize a random number generator with a seed\n",
    "    rng = NumpyRandomWrapper(seed)\n",
    "    nsga2 = NSGA2(rng)\n",
    "    # Run the NSGA2\n",
    "    (\n",
    "        final_pop_candidates,\n",
    "        final_pop_fitnesses,\n",
    "        all_populations_fitnesses,\n",
    "    ) = nsga2.run_nsga2(problem, num_vars=3, **args)\n",
    "    # Compute the statistics of the Pareto front\n",
    "    results = compute_pareto_front_statistics(\n",
    "        final_pop_candidates, final_pop_fitnesses, 2\n",
    "    )\n",
    "    best_f1_fitness.append(results[0][1].item())\n",
    "    best_f2_fitness.append(results[1][1].item())\n",
    "    best_origin_fitness.append(results[2][1].item())\n",
    "\n",
    "    if best_seed is None or overall_best is None or results[2][1][0] < overall_best:\n",
    "        best_seed = seed\n",
    "        overall_best = results[2][1][0]\n",
    "\n",
    "    # Print the results\n",
    "    # print(f\"Best solution for objective f1 for iteration {sim}: \", results[0][0])\n",
    "    # print(f\"Best fitness for objective f1 for iteration {sim}: \", results[0][1])\n",
    "    # print(f\"Best solution for objective f2 for iteration {sim}: \", results[1][0])\n",
    "    # print(f\"Best fitness for objective f2 for iteration {sim}: \", results[1][1])\n",
    "    # print(f\"Best solution closest to the origin for iteration {sim}: \", results[2][0])\n",
    "    # print(f\"Best fitness closest to the origin for iteration {sim}: \", results[2][1])\n",
    "\n",
    "# Print the mean and standard deviation of the best fitness\n",
    "print(\"Mean fitness for f1: \", pl.mean(best_f1_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f1: \", pl.std(best_f1_fitness, axis=0))\n",
    "print(\"Mean fitness for f2: \", pl.mean(best_f2_fitness, axis=0))\n",
    "print(\"Standard deviation of fitness for f2: \", pl.std(best_f2_fitness, axis=0))\n",
    "print(\"Mean fitness closest ti origin: \", pl.mean(best_origin_fitness, axis=0))\n",
    "print(\"Standard deviation closest to fitness: \", pl.std(best_origin_fitness, axis=0))\n",
    "\n",
    "nsga2 = NSGA2(NumpyRandomWrapper(best_seed))\n",
    "final_pop_candidates, final_pop_fitnesses, all_populations_fitnesses = nsga2.run_nsga2(\n",
    "    problem, num_vars=3, **args\n",
    ")\n",
    "# print(\"Best solutions: \", final_pop_candidates)\n",
    "# print(\"Best fitnesses: \", final_pop_fitnesses)\n",
    "\n",
    "plot_pareto(final_pop_fitnesses, (\"f1\", \"f2\"))\n",
    "plot_pareto_rank(all_populations_fitnesses, (\"f1\", \"f2\"))\n",
    "results = compute_pareto_front_statistics(final_pop_candidates, final_pop_fitnesses, 2)\n",
    "print(f\"Best solution for objective f1 for iteration {sim}: \", results[0][0])\n",
    "print(f\"Best fitness for objective f1 for iteration {sim}: \", results[0][1])\n",
    "print(f\"Best solution for objective f2 for iteration {sim}: \", results[1][0])\n",
    "print(f\"Best fitness for objective f2 for iteration {sim}: \", results[1][1])\n",
    "print(f\"Best solution closest to the origin for iteration {sim}: \", results[2][0])\n",
    "print(f\"Best fitness closest to the origin for iteration {sim}: \", results[2][1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "11mcwlyXuGjQ",
    "MOi-e1R5vPGB",
    "3Dz99sJ7vSM8",
    "skFzrMTIwCV-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
