{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEo6J_FPTUmX"
   },
   "source": [
    "# Lab. 9: Design of Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRtpQcNARkYB"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "#### <u>The goal of this lab is observe the effect of the DoE in the Bayesian optimization and Bio-inspired approaches.</u>\n",
    "\n",
    "You'll have to implement four sampling methods:\n",
    "\n",
    "Random sampling\n",
    "The Halton sequence\n",
    "The full factorial sampling\n",
    "The Latin Hypercube sampling\n",
    "\n",
    "- *Random sampling*\n",
    "- *The Halton sequence*\n",
    "- *The full factorial sampling*\n",
    "- *The Latin Hypercude sampling*\n",
    "---\n",
    "\n",
    "Getting started: The following cells contain the implementation of the methods that we will use throughout this lab, together with utilities.\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "When studying the effect of the parameters is extremely important to vary just one parameter at a time. Therefore, it is suggested to study one parameter by fixing all the others, and then moving to the next.\n",
    "\n",
    "Moreover, when comparing different algorithms, is very important to run each of them several times (e.g., 30) by using different initial random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38284,
     "status": "ok",
     "timestamp": 1715271222490,
     "user": {
      "displayName": "Chiara Camilla Rambaldi Migliore",
      "userId": "14825705546977676123"
     },
     "user_tz": -120
    },
    "id": "ETobOVsD18Yb"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "from typing import Any, Optional\n",
    "\n",
    "import benchmark_functions as bf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from inspyred import ec\n",
    "from inspyred.ec import Individual, replacers, selectors, terminators, variators\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1715271222490,
     "user": {
      "displayName": "Chiara Camilla Rambaldi Migliore",
      "userId": "14825705546977676123"
     },
     "user_tz": -120
    },
    "id": "3kCkQt0y4Ene"
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "GLOBAL = \"Global\"\n",
    "INDIVIDUAL = \"Individual\"\n",
    "CORRELATED = \"Correlated\"\n",
    "STAR = \"star\"\n",
    "RING = \"ring\"\n",
    "\n",
    "\n",
    "class GeneratorType(Enum):\n",
    "    RANDOM = \"random\"\n",
    "    LHS = \"LHS\"\n",
    "    HALTON = \"Halton\"\n",
    "    FF = \"FF\"\n",
    "    RANDOM_2D = \"random_2d\"\n",
    "    LHS_2D = \"LHS_2d\"\n",
    "    HALTON_2D = \"Halton_2d\"\n",
    "    FF_2D = \"FF_2d\"\n",
    "\n",
    "\n",
    "class NumpyRandomWrapper(pl.RandomState):\n",
    "    def __init__(self, seed: Optional[int] = None) -> None:\n",
    "        super(NumpyRandomWrapper, self).__init__(seed)\n",
    "\n",
    "    def sample(self, pop: int | list[float], k: int) -> NDArray[np.float64]:\n",
    "        population: list[int] | list[float] = []\n",
    "        if isinstance(pop, int):\n",
    "            population = list(range(pop))\n",
    "        else:\n",
    "            population = deepcopy(pop)\n",
    "\n",
    "        return np.asarray(\n",
    "            [\n",
    "                population[i]\n",
    "                for i in self._choice_without_replacement(len(population), k)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def random(self) -> float:  # type: ignore\n",
    "        return self.random_sample()\n",
    "\n",
    "    def gauss(self, mu: float, sigma: float) -> float:\n",
    "        return self.normal(mu, sigma)\n",
    "\n",
    "    def _choice_without_replacement(self, n: int, size: int) -> set[int]:\n",
    "        result: set[int] = set()\n",
    "        while len(result) < size:\n",
    "            result.add(self.randint(0, n))\n",
    "        return result\n",
    "\n",
    "\n",
    "class OptFun:\n",
    "    def __init__(self, wf: bf.BenchmarkFunction) -> None:\n",
    "        self.f = wf\n",
    "        self.history: list[list[float]] = []\n",
    "        self.__name__ = f\"OptFun({wf.__class__})\"\n",
    "\n",
    "    def __call__(\n",
    "        self, candidates: list[list[float]], *args: Any, **kwargs: Any\n",
    "    ) -> list[float]:\n",
    "        \"\"\"\n",
    "        Evaluate the objective function for a list of candidates.\n",
    "        \"\"\"\n",
    "        y: list[float] = []\n",
    "        for x0 in candidates:\n",
    "            self.history.append(deepcopy(x0))\n",
    "            y.append(self.f(x0))  # type: ignore\n",
    "        return y\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.f.name()\n",
    "\n",
    "    def minima(self) -> list[bf.fil.Optimum]:\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounder(self) -> Any:\n",
    "        def fcn(candidate: list[float], *args: Any) -> list[float]:\n",
    "            bounds: tuple[list[float], list[float]] = self.f.suggested_bounds()\n",
    "\n",
    "            for i, (m, M) in enumerate(zip(*bounds)):\n",
    "                if candidate[i] < m:\n",
    "                    candidate[i] = m\n",
    "                if candidate[i] > M:\n",
    "                    candidate[i] = M\n",
    "            return candidate\n",
    "\n",
    "        return fcn\n",
    "\n",
    "    def bounds(self) -> list[tuple[float, float]]:\n",
    "        \"\"\"\n",
    "        Return the bounds of the objective function.\n",
    "        \"\"\"\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, fn: Optional[str] = None) -> None:\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(\"Benchmark Function: \" + self.f.name())\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f.n_dimensions() > 1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray(\n",
    "                [\n",
    "                    [self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))]\n",
    "                    for i in range(len(X))\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Function has only one dimension\")\n",
    "\n",
    "        plt.contour(x, y, Z, 15, linewidths=0.5, colors=\"k\")  # hight lines\n",
    "        plt.contourf(\n",
    "            x, y, Z, 15, cmap=\"viridis\", vmin=Z.min(), vmax=Z.max()\n",
    "        )  # heat map\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"z\")\n",
    "        if len(self.history) > 0:  # plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            plt.plot(xdata, ydata, \"or-\", markersize=3, linewidth=1)\n",
    "        if fn is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "\n",
    "    def plot_population_evolution(\n",
    "        self,\n",
    "        populations: list[list[NDArray[np.float64]]],\n",
    "        generation_step: int = 1,\n",
    "        single: bool = False,\n",
    "        grid: bool = False,\n",
    "        args: dict[str, Any] = {},\n",
    "        title: str = \"\",\n",
    "        optima: Optional[list[float]] = None,\n",
    "    ) -> None:\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        if single:\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "            ax = [ax]\n",
    "            fig.set_figwidth(5)\n",
    "            fig.set_figheight(5)\n",
    "        else:\n",
    "            fig, ax = plt.subplots(2, 3)\n",
    "            ax = ax.flatten()\n",
    "            fig.set_figwidth(10)\n",
    "            fig.set_figheight(7)\n",
    "\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f.n_dimensions() > 1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray(\n",
    "                [\n",
    "                    [self.f((X[i][j], Y[i][j])) for j in range(len(X[i]))]\n",
    "                    for i in range(len(X))\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Function has only one dimension\")\n",
    "\n",
    "        for i in range(min(len(populations), 6)):\n",
    "            if i * generation_step < len(populations):\n",
    "                ax[i].contour(x, y, Z, 15, linewidths=0.5, colors=\"k\")\n",
    "                ax[i].contourf(\n",
    "                    x, y, Z, 15, cmap=\"viridis\", vmin=Z.min(), vmax=Z.max()\n",
    "                )  # heat map\n",
    "                ax[i].set_xlabel(\"x\")\n",
    "                ax[i].set_ylabel(\"y\")\n",
    "                ax[i].set_title(\"Generation \" + str(i * generation_step))\n",
    "                # scatter plot of the population\n",
    "                current_pop = populations[i * generation_step]\n",
    "                xdata = [x[0] for x in current_pop]\n",
    "                ydata = [x[1] for x in current_pop]\n",
    "                ax[i].scatter(xdata, ydata, color=\"r\", zorder=2, label=\"population\")\n",
    "\n",
    "                if optima is not None:\n",
    "                    ax[i].plot(\n",
    "                        optima[0],\n",
    "                        optima[1],\n",
    "                        \"wx\",\n",
    "                        zorder=3,\n",
    "                        markersize=8,\n",
    "                        markeredgewidth=4,\n",
    "                        label=\"optimum\",\n",
    "                    )\n",
    "\n",
    "                if single:\n",
    "                    break\n",
    "\n",
    "        # Add the grid\n",
    "        if single and grid:\n",
    "            # grid_spacing = (args[\"pop_init_range\"][1] - args[\"pop_init_range\"][0])/args[\"pop_size\"]\n",
    "            # intervals = float(grid_spacing)\n",
    "            ax[0].set_yticks(\n",
    "                np.linspace(\n",
    "                    args[\"pop_init_range\"][0],\n",
    "                    args[\"pop_init_range\"][1],\n",
    "                    len(populations[0]) + 1,\n",
    "                ),\n",
    "                minor=False,\n",
    "            )\n",
    "            ax[0].set_xticks(\n",
    "                np.linspace(\n",
    "                    args[\"pop_init_range\"][0],\n",
    "                    args[\"pop_init_range\"][1],\n",
    "                    len(populations[0]) + 1,\n",
    "                ),\n",
    "                minor=False,\n",
    "            )\n",
    "            ax[0].grid(\n",
    "                which=\"both\", axis=\"both\", linestyle=\"-\", color=\"k\", linewidth=1.4\n",
    "            )\n",
    "            if optima is not None:\n",
    "                ax[0].plot(\n",
    "                    optima[0],\n",
    "                    optima[1],\n",
    "                    \"wx\",\n",
    "                    zorder=3,\n",
    "                    markersize=8,\n",
    "                    markeredgewidth=4,\n",
    "                    label=\"optimum\",\n",
    "                )\n",
    "\n",
    "        handles, labels = ax[0].get_legend_handles_labels()\n",
    "        fig.suptitle(title)\n",
    "        fig.legend(handles, labels, loc=\"upper right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot(self) -> None:\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        min = self.minima()[0].score\n",
    "        if min is None:\n",
    "            raise ValueError(\"No minimum found\")\n",
    "        plt.plot(values)\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(\n",
    "        self, bounds: tuple[list[float], list[float]]\n",
    "    ) -> list[tuple[float, float]]:\n",
    "        new_bounds: list[tuple[float, float]] = []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self) -> int:\n",
    "        return len(self.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_pop_observer(\n",
    "    population: list[Individual],\n",
    "    num_generations: int,\n",
    "    num_evaluations: int,\n",
    "    args: dict[str, Any],\n",
    ") -> None:\n",
    "    if num_generations == 0:\n",
    "        args[\"initial_pop_storage\"][\"individuals\"] = np.asarray(\n",
    "            [guy.candidate for guy in population]\n",
    "        )\n",
    "        args[\"initial_pop_storage\"][\"fitnesses\"] = np.asarray(\n",
    "            [guy.fitness for guy in population]\n",
    "        )\n",
    "\n",
    "\n",
    "def generator_wrapper(func: Any) -> Any:\n",
    "    @functools.wraps(func)\n",
    "    def _generator(\n",
    "        random: NumpyRandomWrapper, args: dict[str, Any]\n",
    "    ) -> NDArray[np.float64]:\n",
    "        return np.asarray(func(random, args))\n",
    "\n",
    "    return _generator\n",
    "\n",
    "\n",
    "# helper function used to store the various populations at each generation\n",
    "def my_archiver(\n",
    "    random: NumpyRandomWrapper,\n",
    "    population: list[Individual],\n",
    "    archive: list[list[Individual]],\n",
    "    args: dict[str, Any],\n",
    ") -> list[list[Individual]]:\n",
    "    archive.append(population)\n",
    "    return archive\n",
    "\n",
    "\n",
    "def run_ga(\n",
    "    random: NumpyRandomWrapper,\n",
    "    generator_type: str,\n",
    "    func: OptFun,\n",
    "    num_vars: int = 0,\n",
    "    maximize: bool = False,\n",
    "    **kwargs: Any,\n",
    ") -> tuple[\n",
    "    NDArray[np.float64], float, list[Individual], list[list[NDArray[np.float64]]]\n",
    "]:\n",
    "    \"\"\"Run the genetic algorithm on the given function.\n",
    "\n",
    "    Args:\n",
    "        random: Random number generator.\n",
    "        generator_type\n",
    "        func: Objective function.\n",
    "        num_vars: Number of variables.\n",
    "        maximize: Whether to maximize the function.\n",
    "        kwargs: Additional arguments.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Best candidate, best fitness, final population, all populations.\n",
    "    \"\"\"\n",
    "    # create dictionaries to store data about initial population, and lines\n",
    "    initial_pop_storage: dict[Any, Any] = {}\n",
    "\n",
    "    algorithm = ec.EvolutionaryComputation(random)\n",
    "    algorithm.terminator = terminators.generation_termination\n",
    "    algorithm.replacer = replacers.generational_replacement\n",
    "    algorithm.variator = [  # type: ignore\n",
    "        variators.uniform_crossover,\n",
    "        variators.gaussian_mutation,\n",
    "    ]\n",
    "    algorithm.selector = selectors.tournament_selection\n",
    "    algorithm.archiver = my_archiver\n",
    "    algorithm.observer = initial_pop_observer\n",
    "\n",
    "    kwargs[\"num_selected\"] = kwargs[\"pop_size\"]\n",
    "    kwargs[\"bounder\"] = func.bounder()\n",
    "    kwargs[\"n_vars\"] = num_vars\n",
    "    kwargs[\"generator\"] = generator(generator_type, random, kwargs)  # type: ignore\n",
    "\n",
    "    final_pop: list[Individual] = algorithm.evolve(\n",
    "        evaluator=func,\n",
    "        maximize=False,\n",
    "        initial_pop_storage=initial_pop_storage,\n",
    "        num_vars=num_vars,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    all_populations: list[list[Individual]] = algorithm.archive  # type: ignore\n",
    "    all_pop: list[list[NDArray[np.float64]]] = [] * len(all_populations)\n",
    "    for i in range(len(all_populations)):\n",
    "        all_pop.append([elem.candidate for elem in all_populations[i]])  # type: ignore\n",
    "\n",
    "    # best_guy = final_pop[0].candidate\n",
    "    # best_fitness = final_pop[0].fitness\n",
    "    final_pop_fitnesses = np.asarray([guy.fitness for guy in final_pop])\n",
    "    final_pop_candidates = np.asarray([guy.candidate for guy in final_pop])\n",
    "\n",
    "    sort_indexes = sorted(\n",
    "        range(len(final_pop_fitnesses)), key=final_pop_fitnesses.__getitem__\n",
    "    )\n",
    "    final_pop_fitnesses = final_pop_fitnesses[sort_indexes]\n",
    "    final_pop_candidates = final_pop_candidates[sort_indexes]\n",
    "\n",
    "    best_guy = final_pop_candidates[0]\n",
    "    best_fitness = final_pop_fitnesses[0]\n",
    "\n",
    "    return best_guy, best_fitness, final_pop, all_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHi6zhHiTQ5a"
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPMZxvbi2VIC"
   },
   "source": [
    "### Exercise 1/3: Implement different sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt-ofafvSw86"
   },
   "outputs": [],
   "source": [
    "def random_generator(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    return random.uniform(\n",
    "        args[\"pop_init_range\"][0], args[\"pop_init_range\"][1], args[\"pop_size\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def random_generator_2d(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    seq1 = random_generator(random, args)\n",
    "    seq2 = random_generator(random, args)\n",
    "\n",
    "    return np.asarray(list(zip(seq1, seq2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkWTCUh02h3d"
   },
   "outputs": [],
   "source": [
    "def Halton_generator(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    b = args[\"base\"]\n",
    "    res = np.zeros(args[\"pop_size\"])\n",
    "    for i in range(args[\"pop_size\"]):\n",
    "        f = 1\n",
    "        r = 0\n",
    "        n = i\n",
    "        while n > 0:\n",
    "            f = f / b\n",
    "            r = r + f * (n % b)\n",
    "            n = n // b\n",
    "        res[i] = r\n",
    "\n",
    "    # scale the result to the desired range\n",
    "    return np.asarray(\n",
    "        [\n",
    "            args[\"pop_init_range\"][0]\n",
    "            + x * (args[\"pop_init_range\"][1] - args[\"pop_init_range\"][0])\n",
    "            for x in res\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def Halton_generator_2d(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    bases = args[\"bases\"]\n",
    "    args[\"base\"] = bases[0]\n",
    "    seq1 = Halton_generator(random, args)\n",
    "    args[\"base\"] = bases[1]\n",
    "    seq2 = Halton_generator(random, args)\n",
    "\n",
    "    return np.asarray(list(zip(seq1, seq2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCmkrZkW2jCd"
   },
   "outputs": [],
   "source": [
    "# Latin Hypercube Sampling\n",
    "def lhs_generator(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any], n: int = 1\n",
    ") -> NDArray[np.float64]:\n",
    "    m: int = args[\"pop_size\"]\n",
    "    perms = np.tile(np.arange(1, m + 1), (n, 1)).T  # M N\n",
    "\n",
    "    samples = random.uniform(size=(m, n))\n",
    "    samples = (perms - samples) / m\n",
    "    for i in range(n):\n",
    "        random.shuffle(samples[:, i])\n",
    "\n",
    "    # Rescale the samples to the given ranges\n",
    "    for i in range(n):\n",
    "        samples[:, i] = (\n",
    "            samples[:, i] * (args[\"pop_init_range\"][1] - args[\"pop_init_range\"][0])\n",
    "            + args[\"pop_init_range\"][0]\n",
    "        )\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def lhs_generator_2d(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    return lhs_generator(random, args, args[\"n_vars\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO5ZzU0H2kBa"
   },
   "outputs": [],
   "source": [
    "# Full Factorial\n",
    "from itertools import product\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def ff_generator(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    divisions = ceil(args[\"pop_size\"] ** (1 / args[\"n_vars\"]))\n",
    "\n",
    "    return np.linspace(\n",
    "        args[\"pop_init_range\"][0],\n",
    "        args[\"pop_init_range\"][1],\n",
    "        divisions,\n",
    "    )\n",
    "\n",
    "\n",
    "def ff_generator_2d(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    seq1 = ff_generator(random, args)\n",
    "    seq2 = ff_generator(random, args)\n",
    "\n",
    "    return np.asarray([x for x in product(seq1, seq2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(case: str, random: NumpyRandomWrapper, args: dict[str, Any]) -> Any:\n",
    "    if case == \"random\":\n",
    "        args[\"sequence\"] = random_generator(random, args)\n",
    "    if case == \"LHS\":\n",
    "        args[\"sequence\"] = lhs_generator(random, args)\n",
    "    if case == \"Halton\":\n",
    "        args[\"sequence\"] = Halton_generator(random, args)\n",
    "    if case == \"FF\":\n",
    "        args[\"sequence\"] = ff_generator(random, args)\n",
    "    if case == \"random_2d\":\n",
    "        args[\"sequence\"] = random_generator_2d(random, args)\n",
    "    if case == \"LHS_2d\":\n",
    "        args[\"sequence\"] = lhs_generator_2d(random, args)\n",
    "    if case == \"Halton_2d\":\n",
    "        args[\"sequence\"] = Halton_generator_2d(random, args)\n",
    "    if case == \"FF_2d\":\n",
    "        args[\"sequence\"] = ff_generator_2d(random, args)\n",
    "    args[\"index\"] = 0\n",
    "    return fake_generator\n",
    "\n",
    "\n",
    "def fake_generator(\n",
    "    random: NumpyRandomWrapper, args: dict[str, Any]\n",
    ") -> NDArray[np.float64]:\n",
    "    index = args[\"index\"]\n",
    "    args[\"index\"] += 1\n",
    "\n",
    "    return args[\"sequence\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw5qPvKv2nZd"
   },
   "source": [
    "### Exercise 2/3: Visualize the implemented methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmB1kMFi2mxT"
   },
   "outputs": [],
   "source": [
    "def plot_sampled_point(sample_method: str, args: dict[str, Any]) -> None:\n",
    "    sample: NDArray[np.float64] = np.asarray([0, 0])\n",
    "    match sample_method:\n",
    "        case \"random\":\n",
    "            sample = random_generator(NumpyRandomWrapper(), args)\n",
    "        case \"LHS\":\n",
    "            sample = lhs_generator(NumpyRandomWrapper(), args)\n",
    "        case \"Halton\":\n",
    "            sample = Halton_generator(NumpyRandomWrapper(), args)\n",
    "        case \"FF\":\n",
    "            sample = ff_generator(NumpyRandomWrapper(), args)\n",
    "        case \"random_2d\":\n",
    "            sample = random_generator_2d(NumpyRandomWrapper(), args)\n",
    "        case \"LHS_2d\":\n",
    "            sample = lhs_generator_2d(NumpyRandomWrapper(), args)\n",
    "        case \"Halton_2d\":\n",
    "            sample = Halton_generator_2d(NumpyRandomWrapper(), args)\n",
    "        case \"FF_2d\":\n",
    "            sample = ff_generator_2d(NumpyRandomWrapper(), args)\n",
    "        case _:\n",
    "            raise ValueError(\"Invalid sample method\")\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    f.suptitle(\"Sampled point from \" + sample_method)\n",
    "    print(sample.shape)\n",
    "    if len(sample.shape) == 1:\n",
    "        ax.scatter(sample, np.ones(len(sample)), color=\"r\")\n",
    "        ax.yaxis.set_visible(False)\n",
    "    else:\n",
    "        plt.scatter(sample[:, 0], sample[:, 1], color=\"r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampled_point(\n",
    "    \"LHS_2d\",\n",
    "    {\n",
    "        \"n_vars\": 2,\n",
    "        \"pop_init_range\": [0, 1],\n",
    "        \"pop_size\": 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampled_point(\n",
    "    \"Halton_2d\",\n",
    "    {\n",
    "        \"pop_init_range\": [0, 1],\n",
    "        \"pop_size\": 100,\n",
    "        \"bases\": [2, 3],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampled_point(\n",
    "    \"FF_2d\",\n",
    "    {\n",
    "        \"n_vars\": 2,\n",
    "        \"pop_init_range\": [0, 1],\n",
    "        \"pop_size\": 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampled_point(\n",
    "    \"random_2d\",\n",
    "    {\n",
    "        \"pop_init_range\": [0, 1],\n",
    "        \"pop_size\": 100,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "550ldiUt24jZ"
   },
   "source": [
    "### Exercise 3/3: Genetic algorithm - testing different initial sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(\n",
    "    fun: OptFun, method: str, num_simulations: int, plot: bool, args: dict[str, Any]\n",
    ") -> tuple[float, float, float]:\n",
    "    best_fitnesses: list[float] = []\n",
    "    all_pops: list[list[list[NDArray[np.float64]]]] = []\n",
    "    best_sim = None\n",
    "    best_sim_index = 0\n",
    "\n",
    "    start = time()\n",
    "    for i in range(num_simulations):\n",
    "        _, best_fitness, _, all_pop = run_ga(\n",
    "            NumpyRandomWrapper(),\n",
    "            method,\n",
    "            fun,\n",
    "            num_vars=fun.f.n_dimensions(),\n",
    "            maximize=False,\n",
    "            **args,\n",
    "        )\n",
    "        best_fitnesses.append(best_fitness)\n",
    "        all_pops.append(all_pop)\n",
    "\n",
    "        if best_sim is None or best_fitness < best_sim:\n",
    "            best_sim = best_fitness\n",
    "            best_sim_index = i\n",
    "\n",
    "    end = time()\n",
    "    if plot:\n",
    "        fun.plot_population_evolution(\n",
    "            all_pops[best_sim_index],\n",
    "            generation_step=4,\n",
    "            single=False,\n",
    "            grid=True,\n",
    "            args=args,\n",
    "            title=f\"{fun.name} - {method}\",\n",
    "            optima=fun.minima()[0].position,  # type: ignore\n",
    "        )\n",
    "\n",
    "    mean_best_fitness = np.mean(best_fitnesses)\n",
    "    std_best_fitness = np.std(best_fitnesses)\n",
    "\n",
    "    return mean_best_fitness.item(), std_best_fitness.item(), end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = OptFun(bf.Ackley(2))\n",
    "args: dict[str, Any] = {}\n",
    "args[\"gaussian_stdev\"] = 0.5  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 49  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 20  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.7\n",
    "args[\"mutation_rate\"] = 0.2\n",
    "args[\"initial_pop_size\"] = args[\"pop_size\"]\n",
    "args[\"bases\"] = [2, 3]\n",
    "\n",
    "num_simulations = 30\n",
    "sampling_methods = [\"Halton_2d\", \"LHS_2d\", \"FF_2d\", \"random_2d\"]\n",
    "\n",
    "for method in sampling_methods:\n",
    "    func = OptFun(bf.Ackley(2))\n",
    "    mean, std, t = run_algorithm(func, method, num_simulations, True, args)\n",
    "    print(f\"{method}: {mean} ± {std}\")\n",
    "    print(f\"Time: {t} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = OptFun(bf.Rosenbrock(2))\n",
    "\n",
    "args: dict[str, Any] = {}\n",
    "args[\"gaussian_stdev\"] = 0.1  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 49  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 20  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.7\n",
    "args[\"mutation_rate\"] = 0.2\n",
    "args[\"initial_pop_size\"] = args[\"pop_size\"]\n",
    "args[\"bases\"] = [2, 3]\n",
    "\n",
    "sampling_methods = [\"Halton_2d\", \"LHS_2d\", \"FF_2d\", \"random_2d\"]\n",
    "num_simulations = 30\n",
    "\n",
    "for method in sampling_methods:\n",
    "    func = OptFun(bf.Rosenbrock(2))\n",
    "    mean, std, t = run_algorithm(func, method, num_simulations, True, args)\n",
    "    print(f\"{method}: {mean} ± {std}\")\n",
    "    print(f\"Time: {t} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = OptFun(bf.DeJong5())\n",
    "\n",
    "args: dict[str, Any] = {}\n",
    "args[\"gaussian_stdev\"] = 0.1  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 81  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 20  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.7\n",
    "args[\"mutation_rate\"] = 0.2\n",
    "args[\"initial_pop_size\"] = args[\"pop_size\"]\n",
    "args[\"bases\"] = [2, 3]\n",
    "\n",
    "sampling_methods = [\"Halton_2d\", \"LHS_2d\", \"FF_2d\", \"random_2d\"]\n",
    "num_simulations = 30\n",
    "\n",
    "for method in sampling_methods:\n",
    "    func = OptFun(bf.DeJong5())\n",
    "    mean, std, t = run_algorithm(func, method, num_simulations, True, args)\n",
    "    print(f\"{method}: {mean} ± {std}\")\n",
    "    print(f\"Time: {t} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = OptFun(bf.Keane())\n",
    "\n",
    "args: dict[str, Any] = {}\n",
    "args[\"gaussian_stdev\"] = 0.1  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 49  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 20  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.7\n",
    "args[\"mutation_rate\"] = 0.2\n",
    "args[\"initial_pop_size\"] = args[\"pop_size\"]\n",
    "args[\"bases\"] = [2, 3]\n",
    "\n",
    "sampling_methods = [\"Halton_2d\", \"LHS_2d\", \"FF_2d\", \"random_2d\"]\n",
    "num_simulations = 30\n",
    "\n",
    "for method in sampling_methods:\n",
    "    func = OptFun(bf.Keane())\n",
    "    mean, std, t = run_algorithm(func, method, num_simulations, True, args)\n",
    "    print(f\"{method}: {mean} ± {std}\")\n",
    "    print(f\"Time: {t} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = OptFun(bf.Rastrigin())\n",
    "\n",
    "args: dict[str, Any] = {}\n",
    "args[\"gaussian_stdev\"] = 0.1  # Standard deviation of the Gaussian mutations\n",
    "args[\"tournament_size\"] = 2\n",
    "args[\"num_elites\"] = 1  # number of elite individuals to maintain in each gen\n",
    "args[\"pop_size\"] = 49  # population size\n",
    "args[\"pop_init_range\"] = func.bounds()[0]  # Range for the initial population\n",
    "args[\"max_generations\"] = 20  # Number of generations of the GA\n",
    "args[\"crossover_rate\"] = 0.7\n",
    "args[\"mutation_rate\"] = 0.2\n",
    "args[\"initial_pop_size\"] = args[\"pop_size\"]\n",
    "args[\"bases\"] = [2, 3]\n",
    "\n",
    "sampling_methods = [\"Halton_2d\", \"LHS_2d\", \"FF_2d\", \"random_2d\"]\n",
    "num_simulations = 30\n",
    "\n",
    "for method in sampling_methods:\n",
    "    func = OptFun(bf.Rastrigin())\n",
    "    mean, std, t = run_algorithm(func, method, num_simulations, True, args)\n",
    "    print(f\"{method}: {mean} ± {std}\")\n",
    "    print(f\"Time: {t} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmmGvxfnAFol"
   },
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt_KJIL1AHOs"
   },
   "source": [
    "Compare the GA studied in the previous lessons with its enhanced version with different DOE techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fipAnVIbzWq9"
   },
   "source": [
    "#### 1. **How do the performances increases? Are the algorithms faster to converge, or can they find better solutions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNN3sqCBzS2t"
   },
   "source": [
    "#### 2. **Is there an approach better than the others in terms of performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnYADps8zUP8"
   },
   "source": [
    "#### 3. **How much do the DOEs affect the search cost?**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
